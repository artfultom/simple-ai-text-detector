# Simple AI Text Detector

Проект для детекции текстов, сгенерированных искусственным интеллектом.

## Описание проекта

### Постановка задачи

Определить, к какому классу относится текст:
1. Полностью сгенерирован ИИ (LLM)
2. Полностью написан человеком

### Формат данных

**Вход:** текст на английском языке

**Выход:** бинарный флаг, показывающий, был ли текст сгенерирован ИИ

### Метрики качества

**F1-score** - основная метрика для оценки качества модели. Выбрана как наиболее универсальная для задач бинарной классификации, работает с несбалансированными классами и учитывает как precision, так и recall.

### Валидация

Используется стратегия train/validation/test split в соотношении 70/15/15.

Для предотвращения переобучения:
- Test набор остается нетронутым до финального тестирования

Для воспроизводимости результатов:
- Фиксированный seed=42
- Зафиксированные версии всех библиотек
- Сохранение всех артефактов обучения

### Данные

**Датасет:** [AI vs Human Text](https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text/data)

**Размер:** 500,000 эссе (написанных людьми и сгенерированных ИИ)

**ВАЖНО:** для удобства проверяющего установлен параметр `total_size=10000`, ограничивающий размер датасета и ускоряющий обучение. Его можно переопределить на этапе train, передав параметром cli.

**Известные ограничения:**
- Несбалансированность классов
- Отсутствие информации о параметрах генерации ИИ-текстов
- Возможные вопросы к качеству генерации в датасете

### Архитектура решения

#### Baseline модель

TF-IDF + Logistic Regression

Препроцессинг включает:
- Удаление стоп-слов
- Лемматизацию
- Нормализацию текста

#### Основная модель

**BERT (base)** с fine-tuning на датасете
- 12 трансформерных слоев
- Fine-tuning всех слоев модели
- Мониторинг метрик через MLflow

## Setup

### Требования

- Python 3.12
- uv для управления зависимостями
- git

### Установка окружения

#### С использованием uv

```bash
cd path/to/project
uv sync
```

### Загрузка данных

```bash
./.venv/bin/python ./commands.py download_data
```

## Train

### Запуск обучения

#### Baseline модель

```bash
# Обучение baseline модели с дефолтными параметрами
./.venv/bin/python ./commands.py baseline

# Обучение с кастомным параметром
./.venv/bin/python ./commands.py baseline --total_size=400000
```

#### BERT модель

```bash
# Обучение BERT модели с дефолтными параметрами
./.venv/bin/python ./commands.py model

# Обучение с кастомным параметром
./.venv/bin/python ./commands.py model --total_size=400000
```

### Конфигурация

Все конфигурационные файлы находятся в директории `configs/`:

- `model/baseline.yaml` - параметры baseline модели
- `data/data.yaml` - параметры датасета
- `download_data/download_data.yaml` - конфиг локальной загрузки данных
- `model/bert.yaml` - параметры BERT модели
- `config.yaml` - основной конфиг

Для изменения параметров можно либо отредактировать yaml файлы, либо передать параметры через командную строку.

## Inference

Не входит в скоуп задания.

## Мониторинг

Метрики обучения логируются в MLflow, для локального запуска которого в репозиторий добавлен `./mlflow/docker-compose.yml`.

```bash
cd ./mlflow
docker-compose up
```

Затем откройте браузер по адресу http://127.0.0.1:8080

## Разработка

### Code Quality

Проект использует следующие инструменты для поддержания качества кода:

- **ruff** - линтинг и форматирование
- **pre-commit** - автоматические проверки перед коммитом

Запуск проверок вручную:

```bash
# Запуск всех pre-commit хуков
uv run pre-commit run -a
```
